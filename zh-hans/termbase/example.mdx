---
title: 术语表
---

LLM (Large Language Model) - 大型语言模型
LLM 是一种能够理解和生成人类语言的 AI 模型，如 OpenAI 的 GPT 系列、Anthropic 的 Claude 等。

RAG (Retrieval-Augmented Generation) - 检索增强生成
RAG 是一种技术架构，它结合了检索系统和生成模型，通过从外部知识库中检索相关信息，增强语言模型的回答能力和可靠性。

Prompt - 提示词
Prompt 是指引导 AI 模型生成特定响应的输入文本。精心设计的提示词可以显著提高模型输出的质量和相关性。

Agentic Workflow - 智能体工作流
Agentic Workflow 是一种使用自主代理（Agent）执行任务的工作流程设计，允许 AI 系统通过多个步骤和组件自主解决复杂问题。

ETL (Extract, Transform, Load) - 提取、转换、加载
在 AI 文档处理领域，ETL 指数据从源系统提取、转换为适合分析的格式，并加载到目标系统（如知识库）的过程。

Vector Database - 向量数据库
向量数据库是专门设计用于存储和搜索向量嵌入的数据库系统，在 AI 应用中用于相似性搜索和语义检索。

Text Embedding - 文本嵌入
文本嵌入是将文本转换为数值向量表示的过程，使计算机能够处理和“理解”文本的语义意义。

ReRank - 重排序
ReRank 技术是一种针对初步检索结果进行再次排序的技术，通常用于提高检索结果的相关性。

Rerank 模型
重新排序模型，用于对检索结果进行重新排序以提高相关性。

ASR (Automatic Speech Recognition) - 自动语音识别
自动语音识别是将人类语音转换为文本的技术，是人机交互中的重要组成部分。

Multimodal Model - 多模态模型
多模态模型能够处理和理解多种形式的输入数据，如文本、图像、音频等，使 AI 系统能够更全面地理解信息。

Function Calling - 函数调用
Function Calling 是大型语言模型的一项能力，允许模型识别何时应调用预定义的函数，并以结构化方式提供所需参数。

ReAct (Reasoning and Acting) - 推理与行动
ReAct 是一种结合了推理（Reasoning）和行动（Acting）的 AI 代理框架，使模型能够交替进行思考和行动，处理复杂任务：LLM 首先思考当前状态和目标，然后选择并调用合适的工具，工具的输出结果又将引导 LLM 进行下一步的思考和行动，如此循环，直到问题解决。

TTS (Text-to-Speech) - 文本转语音
文本转语音是将书面文本转换为合成语音的技术，是 AI 语音合成的重要应用。

语音转文字 (Speech-to-Text, STT)
语音转文字是将用户语音输入转换为文本的技术，方便用户使用语音而非文本与AI系统交互。

预定义模型
预定义模型是指已经由 AI 厂商训练好并面向市场的模型，通常是闭源模型（例如 GPT 系列模型和 Claude 系列模型）。用户可以直接调用这些模型能力完成特定任务，无需进行额外的训练或配置。

DSL (Domain-Specific Language) - 领域特定语言
在 AI 开发环境中，DSL 是为特定应用领域设计的编程语言，使非专业开发者也能构建高效的 AI 工作流。Dify DSL 是由 Dify.Al 所定义的 Al 应用工程文件标准，文件格式为 YML。该标准涵盖应用在 Dify 内的本描述、模型参数、编排配置等信息。

Knowledge Base - 知识库
知识库在 AI 应用中是存储结构化信息的数据库，使 AI 系统能够检索和利用这些信息增强其回答。

Vector Retrieval - 向量检索
向量检索是基于文本向量嵌入的相似度搜索，是实现高效语义搜索的关键技术。
 
Multi-path Retrieval - 多路召回
多路召回是一种检索策略，通过多种不同的检索方法并行获取信息，然后合并结果，提高检索系统的全面性和准确性。

MaaS (Model-as-a-Service) - 模型即服务
MaaS 是一种云服务模式，提供商通过 API 暴露预训练的机器学习模型，使用户无需自己部署和维护模型基础设施。

Local Model Inference - 本地模型推理
本地模型推理是在用户自己的硬件上运行 AI 模型的过程，与云端推理相比，此过程可以提供更好的隐私保护和更低的延迟。

Workflow - 工作流
工作流是一种任务编排方式，在 AI 应用开发中，特指将复杂 AI 应用拆分为多个独立节点并按照特定顺序执行的结构化流程。

Agent (智能代理)
Agent 是一种能够自主决策并执行操作的 AI 系统，通常结合了大型语言模型的理解能力和与外部工具交互的能力。

知识检索 (Knowledge Retrieval)
知识检索是 RAG 架构中的关键组件，负责从知识库中找出与用户查询最相关的信息片段，作为 LLM 生成回答的依据。

会话变量 (Session Variables)
会话变量是维持多轮对话上下文连贯性的重要机制，可以存储用户偏好、历史交互信息等，实现真正的"记忆"功能。

记忆 (Memory)
记忆是 AI 系统保存和使用历史交互信息的能力，是保持多轮对话连贯性的关键技术。

Vision (视觉能力)
Vision 是多模态 LLM 的一种能力，允许模型处理和理解用户所上传的图片内容，与文本输入一起综合生成回答。

分段 (Chunking)
分段是将长文本拆分成较小内容块的过程，目的是使检索系统能够更精准地找到与用户问题相关的内容片段，同时考虑大语言模型上下文窗口的限制。

父子分段模式 (Parent-Child Chunking)
父区块（Parent-chunk）保持较大的文本单位（如段落），提供丰富的上下文信息；子区块（Child-chunk）则是较小的文本单位（如句子），用于精确检索。系统首先通过子区块进行精确检索以确保相关性，然后获取对应的父区块来补充上下文信息，从而在生成响应时既保证准确性又能提供完整的背景信息。

通用分段模式
通用分段模式是一种简单的分段策略，将文本拆分为独立的内容块，每个内容块相互独立，适合内容相对独立的文档。

混合检索 (Hybrid Search)
混合检索结合了关键词检索和向量检索的优势，通过权重设置或 Rerank 模型选择最佳结果，能够在各种检索场景中取得更好的效果。

温度 (Temperature)
温度是控制语言模型输出随机性的参数，通常是 0-1 中的一个值。温度越接近 0，结果越确定和重复，温度越接近1，结果越随机。

TopK
TopK 用于筛选与用户问题相似度最高的文本片段，是控制检索结果数量的重要参数。数值越高，预期被召回的文本分段数量越多。

TopP (Nucleus Sampling)
TopP（核采样）是一种文本生成控制方法，它通过只从累积概率达到指定阈值 P 的最可能词汇中进行选择，平衡了文本输出的可预测性和创造性，数值越低则输出越确定，数值越高则结果越多样化。

存在惩罚 (Presence Penalty)
存在惩罚是一种防止语言模型生成重复内容的技术，通过降低已出现词汇的概率来实现。参数值增加时，对于已经生成过的内容，模型在后续生成中被施加更大的惩罚，生成重复内容的可能性越低。

频率惩罚 (Frequency Penalty)
频率惩罚通过降低频繁出现词汇的生成概率，增加语言模型输出的多样性。较高的参数值会减少这些词的出现频率，从而增加文本的词汇多样性。

引用与归属 (Citation and Attribution)
引用与归属是 RAG 系统的重要功能，能够标明 AI 回答中信息的来源，增加透明度和可信度。

Score 阈值 (Threshold)
Score 阈值是一种过滤机制，用于设置文本片段筛选的相似度阈值，只召回超过设置分数的文本片段。数值越高说明对文本与问题要求的相似度越高，预期被召回的文本数量也越少。

倒排索引 (Inverted Index)
倒排索引是一种数据结构，它将每个词映射到包含它的文档列表，是全文检索系统的核心组件。这是一种用于快速检索文档中关键词的索引结构，常用于在线搜索引擎。

Q&A 模式
Q&A模式是一种特殊的索引策略，通过为文本自动生成问答对，实现问题到问题的匹配，适合FAQ类型的内容。开启该模式后，系统将对已上传的文本进行分段。总结内容后为每个分段自动生成 Q&A 匹配对。与常见的 「Q to P」（用户问题匹配文本段落）策略不同，QA 模式采用 「Q to Q」（问题匹配问题）策略。

召回测试 (Retrieval Test)
召回测试是一种验证知识库检索效果的功能，允许开发者模拟用户查询，评估检索结果的相关性和准确性。

语义检索 (Semantic Search)
语义检索是一种基于向量相似度的检索方法，能够理解查询的语义而不仅仅是关键词，特别适合复杂查询和跨语言场景。即便知识库中没有出现查询中的确切词汇，也能通过计算向量距离的方式提高搜索的深度，返回正确内容。此外，当需要处理多语言内容时，语义检索能够捕捉不同语言之间的意义转换，提供更加准确的跨语言搜索结果。

关键词检索 (Keyword Search)
关键词检索是一种基于精确匹配的检索方法，适合用户知道确切术语的场景，计算资源消耗较低。

元数据筛选 (Metadata Filtering)
元数据筛选是一种通过文档属性信息进行过滤的方法，能够在检索前缩小文档范围，提高检索效率和精确度。

流式结果返回 (Streaming Response)
流式结果返回是一种响应方式，AI 系统不等待完整回答生成完毕，而是逐步返回生成的内容，提高用户体验和响应感知速度。

工具调用 (Tool Calling)
工具调用是 AI 代理系统的核心能力，指系统能够识别并使用外部工具完成任务，扩展其原有能力范围。

多工具调用 (Multi-tool-call)
模型能够在单次响应中调用多个不同工具的能力。

流式工具调用 (Stream-tool-call)
以流式方式调用工具的能力，允许实时处理和响应。

反向调用
插件能够与 Dify 平台内的功能组件进行双向互动，它能够按照指令主动调用 Dify 的核心功能。

CoT（思维链）
思维链是一种通过引导大语言模型逐步思考问题的方法，使其能够展示推理过程。

ToT（思维树）
思维树是一种探索多个可能的推理路径的方法，允许模型从不同角度思考问题。

GoT（思维图）
思维图是一种将思考过程表示为图形结构的方法，捕捉概念之间的关系。

BoT（思维骨架）
思维骨架是一种用于结构化思考过程的框架，提供推理的主干结构。

响应格式 (Response_format)
指定模型输出的格式类型，如纯文本、JSON 等。

Max_tokens（最大标记数）
模型在单次响应中生成的最大标记（tokens）数量。