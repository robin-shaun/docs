---
title: 术语表
---

## A
### 智能代理（Agent）
智能代理是一种自主 AI 系统，能够根据环境信息做出决策并执行任务。在 Dify 平台中，智能代理结合大语言模型的理解能力与外部工具的交互能力，可以自动完成从简单到复杂的一系列操作，如搜索信息、调用 API 或生成内容。

### 智能体工作流（Agentic Workflow）
智能体工作流是一种任务编排方法，允许 AI 系统通过多个步骤自主解决复杂问题。例如，一个智能体工作流可以先理解用户问题，然后查询知识库，接着调用计算工具，最后整合信息生成完整回答，全程无需人工干预。

### 自动语音识别（ASR, Automatic Speech Recognition）
自动语音识别技术将人类语音转换为文本，是语音交互应用的基础。这项技术使用户可以通过说话而非打字与 AI 系统交互，广泛应用于语音助手、会议记录和无障碍服务等场景。

## B
### 思维骨架（BoT, Backbone of Thought）
思维骨架是一种结构化思考框架，为大语言模型提供推理的主干结构。它帮助模型在处理复杂问题时保持清晰的思考路径，类似于论文的提纲或决策树的骨架。

## C
### 分段（Chunking）
分段是将长文本拆分成较小内容块的处理技术，使检索系统能更精准地找到相关信息。合理的分段策略既要考虑内容的语义完整性，也要满足语言模型的上下文窗口限制，从而提高检索和生成质量。

### 引用与归属（Citation and Attribution）
引用与归属功能让 AI 系统能够清晰标明信息来源，提高响应的可信度和透明度。当系统基于知识库内容生成回答时，可以自动标注引用的文档名称、页码或 URL，让用户了解信息的出处。

### 思维链（CoT, Chain of Thought）
思维链是一种提示技术，引导大语言模型展示其逐步思考过程。例如，解决数学问题时，模型会先列出已知条件，然后按照推理步骤一步步求解，最后得出结论，整个过程类似人类的思考方式。

## D
### 领域特定语言（DSL, Domain-Specific Language）
领域特定语言是为特定应用领域设计的编程语言或配置格式。Dify DSL 是一种基于 YAML 格式的应用工程文件标准，用于定义 AI 应用的各项配置，包括模型参数、提示词设计和工作流编排，使非专业开发者也能构建复杂 AI 应用。

## E
### 提取、转换、加载（ETL, Extract, Transform, Load）
ETL 是数据处理的经典流程：提取原始数据，转换为适合分析的格式，然后加载到目标系统。在 AI 文档处理中，ETL 可能包括从 PDF 提取文本、清理格式、分割内容、计算嵌入向量，最后加载到向量数据库中，为 RAG 系统做准备。

## F
### 全文检索（Full-text Search）
全文检索是索引文档中的所有词汇，从而允许用户查询任意词汇，并返回包含这些词汇的文本片段。这种技术是现代搜索引擎的基础，能够扫描整个文档集合，无论内容规模多大，都能快速定位包含特定字词或短语的内容。全文检索通常结合倒排索引等数据结构实现高效查询，适用于各类文档库、知识库和搜索系统。

### 频率惩罚（Frequency Penalty）
频率惩罚是一种文本生成控制参数，通过降低频繁出现词汇的生成概率来增加输出的多样性。值越高，模型越倾向于使用多样化的词汇和表达方式；值为 0 时，模型不会特意避免重复使用相同词汇。

### 函数调用（Function Calling）
函数调用是大型语言模型的能力，允许模型识别何时需要调用特定函数并提供所需参数。例如，当用户询问天气时，模型可以自动调用天气 API，构造正确的参数格式（城市、日期），然后根据 API 返回结果生成回答。

## G
### 通用分段模式（General Chunking Pattern）
通用分段模式是一种简单的文本分割策略，将文档拆分为相互独立的内容块。这种模式适合结构清晰、段落相对独立的文档，如产品说明书或百科条目，每个分段可以独立理解而不严重依赖上下文。

### 思维图（GoT, Graph of Thought）
思维图是一种将思考过程表示为网络结构的方法，捕捉概念之间的复杂关系。不同于线性的思维链，思维图可以表达分支、循环和多路径的思考模式，适合处理有多个相互关联因素的复杂问题。

## H
### 混合检索（Hybrid Search）
混合检索结合关键词匹配和语义搜索的优势，提供更全面的检索结果。例如，当搜索"苹果营养成分"时，混合检索既能找到包含"苹果"和"营养"关键词的文档，也能找到讨论"水果健康价值"等相关语义的内容，通过权重调整或重排序选出最优结果。

## I
### 倒排索引（Inverted Index）
倒排索引是搜索引擎的核心数据结构，它记录每个词出现在哪些文档中。与传统索引从文档找内容不同，倒排索引从词汇出发找文档，大幅提高全文检索速度。例如，"人工智能"一词的索引项会列出所有包含这个词的文档 ID 和位置。

## K
### 关键词检索（Keyword Search）
关键词检索是基于精确匹配的搜索方法，查找包含特定词汇的文档。这种方法计算效率高，适合用户明确知道要查找的术语的场景，如产品型号、专有名词或特定命令，但可能会漏掉使用同义词或相关概念表达的内容。

### 知识库（Knowledge Base）
知识库是 AI 应用中存储结构化信息的数据库，为模型提供专业知识来源。在 Dify 平台中，知识库可以包含各种文档（PDF、Word、网页等），经过处理后供 AI 检索并用于生成准确、有根据的回答，特别适合构建领域专家型应用。

### 知识检索（Knowledge Retrieval）
知识检索是从知识库中找出与用户问题最相关信息的过程，是 RAG 系统的关键环节。有效的知识检索不仅要找到相关内容，还要控制返回的信息量，避免无关内容干扰模型，同时提供足够背景确保回答准确完整。

## L
### 大型语言模型（LLM, Large Language Model）
大型语言模型是通过海量文本训练的 AI 模型，能够理解和生成人类语言。现代 LLM（如 GPT 系列、Claude 等）可以撰写文章、回答问题、编写代码，甚至进行推理，它们是各种 AI 应用的核心引擎，尤其适合需要语言理解和生成的场景。

### 本地模型推理（Local Model Inference）
本地模型推理是在用户自己的设备上运行 AI 模型的过程，而非依赖云服务。这种方式提供更好的隐私保护（数据不离开本地）和更低的延迟（无需网络传输），适合处理敏感数据或需要离线工作的场景，但通常受限于本地设备的计算能力。

## M
### 模型即服务（MaaS, Model-as-a-Service）
模型即服务是一种云服务模式，提供商通过 API 提供预训练模型的访问。用户无需关心模型的训练、部署和维护，只需调用 API 并支付使用费用，大幅降低了 AI 应用的开发门槛和基础设施成本，适合快速验证想法或构建原型。

### 最大标记数（Max Tokens）
最大标记数控制模型在单次响应中生成的最大字符量。一个标记大约相当于 4 个字符或 3/4 个英文单词。设置合理的最大标记数可以控制回答的长度，避免过于冗长的输出，同时确保完整表达必要信息。例如，一篇简短摘要可能设为 200 标记，而详细报告可能需要 2000 标记。

### 记忆（Memory）
记忆是 AI 系统保存和使用历史交互信息的能力，使多轮对话保持连贯。有效的记忆机制让 AI 能够理解上下文引用、记住用户偏好、追踪长期目标，从而提供个性化且有连续性的用户体验，避免重复询问已提供的信息。

### 元数据筛选（Metadata Filtering）
元数据筛选利用文档属性信息（如标题、作者、日期、分类标签）进行内容过滤。例如，用户可以限定只检索特定日期范围内的技术文档，或只查询特定部门的报告，从而在检索前缩小范围，提高查找效率和结果相关性。

### 多模态模型（Multimodal Model）
多模态模型能处理多种类型的输入数据，如文本、图像、音频等。这类模型打破了传统 AI 的单一感知限制，可以理解图片内容、分析视频场景、识别声音情绪，为更全面的信息理解创造可能，适用于需要跨媒体理解的复杂应用场景。

### 多工具调用（Multi-tool-call）
多工具调用是模型在单次响应中调用多个不同工具的能力。例如，处理"比较北京和上海明天的天气并推荐适合的衣着"这样的请求时，模型可以同时调用两个城市的天气 API，然后基于返回结果给出合理建议，提高处理复杂任务的效率。

### 多路召回（Multi-path Retrieval）
多路召回是通过多种检索方法并行获取信息的策略。例如，系统可以同时使用关键词搜索、语义匹配和知识图谱查询，然后合并筛选结果，提高信息获取的覆盖面和准确性，特别适合处理复杂或模糊的用户查询。

## P
### 父子分段模式（Parent-Child Chunking）
父子分段模式是一种高级文本分割策略，创建两层级的内容块：父区块保留完整上下文，子区块提供精确匹配点。系统先通过子区块确定相关内容位置，再获取对应父区块以提供完整背景，同时兼顾检索精度和上下文完整性，适合处理复杂文档如研究论文或技术手册。

### 存在惩罚（Presence Penalty）
存在惩罚是防止语言模型重复内容的参数设置。它通过降低已出现词汇的生成概率，鼓励模型探索新的表达方式。参数值越高，模型越不倾向于重复之前生成的内容，有助于避免 AI 回答中常见的循环论证或重复叙述问题。

### 预定义模型（Predefined Model）
预定义模型是由 AI 厂商训练并提供的现成模型，用户可以直接调用而无需自行训练。这些闭源模型（如 GPT-4、Claude 等）通常经过大规模训练和优化，能力强大且易于使用，适合快速开发应用或缺乏自主训练资源的团队。

### 提示词（Prompt）
提示词是引导 AI 模型生成特定响应的输入文本。精心设计的提示词能显著提高输出质量，包括明确指令、提供示例、设定格式要求等元素。例如，不同的提示词可以引导同一模型生成学术文章、创意故事或技术分析，是影响 AI 输出的最关键因素之一。

## Q
### 问答模式（Q&A Mode）
问答模式是一种特殊索引策略，为文档内容自动生成问答对，实现"问题到问题"的匹配。当用户提问时，系统会寻找语义相似的预生成问题，然后返回对应答案。这种模式特别适合 FAQ 内容或结构化知识点，能提供更精准的问答体验。

## R
### 检索增强生成（RAG, Retrieval-Augmented Generation）
检索增强生成是结合外部知识检索和语言生成的技术架构。系统首先从知识库检索与用户问题相关的信息，然后将这些信息作为上下文提供给语言模型，生成有依据、准确的回答。RAG 克服了语言模型知识有限和幻觉问题，特别适合需要最新或专业知识的应用场景。

### 推理与行动（ReAct, Reasoning and Acting）
推理与行动是一种 AI 代理框架，使模型能够交替进行思考和执行操作。在解决问题过程中，模型先分析当前状态，制定计划，然后调用合适工具（如搜索引擎、计算器），根据工具返回结果进行下一步思考，形成思考-行动-思考的循环，直到解决问题，适合处理需要多步骤和外部工具的复杂任务。

### 重排序（ReRank）
重排序是对初步检索结果进行二次排序的技术，提高最终结果的相关性。例如，系统可能先通过高效算法快速检索出大量候选内容，然后使用更复杂但精准的模型对这些结果重新评分排序，将最相关的内容置前，平衡了检索效率和结果质量。

### 重新排序模型（Rerank Model）
重新排序模型专门用于评估检索结果与查询的相关性并重新排序。与初步检索不同，这类模型通常采用更复杂的算法，考虑更多语义因素，能更精确地判断内容与用户意图的匹配度。例如，Cohere Rerank 和 BGE Reranker 等模型可显著提升搜索和推荐系统的结果质量。

### 响应格式（Response Format）
响应格式指定模型输出的结构类型，如纯文本、JSON 或 HTML。设置特定的响应格式可以使 AI 输出更容易被程序处理或集成到其他系统。例如，要求模型以 JSON 格式回答可以确保输出具有一致的结构，便于前端应用直接解析和展示。

### 反向调用（Reverse Calling）
反向调用是插件与平台交互的双向机制，允许插件主动调用平台功能。在 Dify 中，这意味着第三方插件不仅能被 AI 调用，还能反过来使用 Dify 的核心功能，如触发工作流或调用其他插件，极大增强了系统的扩展性和灵活性。

### 召回测试（Retrieval Test）
召回测试是验证知识库检索效果的功能，开发者可以模拟用户查询并评估系统返回结果。这种测试帮助开发者了解系统的检索能力边界，发现并修复潜在问题，如漏检、误检或相关度不佳的情况，是优化 RAG 系统不可或缺的工具。

## S
### 分数阈值（Score Threshold）
分数阈值是过滤检索结果的相似度门槛，只有评分超过设定值的内容才会被返回。设置合理的阈值可以避免无关信息干扰模型生成，提高回答的精确性。例如，如果阈值设为 0.8（满分 1.0），则只有高度相关的内容会被采用，但可能导致信息不全；降低阈值则会纳入更多内容但可能引入噪音。

### 语义检索（Semantic Search）
语义检索基于理解和匹配文本意义而非简单关键词匹配的检索方法。它利用向量嵌入技术将文本转换为数学表示，然后计算查询与文档的语义相似度。这种方法能够找到表达方式不同但含义相近的内容，理解同义词和上下文关系，甚至支持跨语言检索，特别适合复杂或自然语言形式的查询。

### 会话变量（Session Variables）
会话变量是存储多轮对话上下文信息的机制，使 AI 能维持连贯交互。例如，系统可以记住用户的偏好（如"简洁回答"）、身份信息或交互历史状态，避免重复询问，提供个性化体验。在 Dify 中，开发者可以定义和管理这些变量，建立真正记住用户的"有记忆"应用。

### 语音转文字（STT, Speech-to-Text）
语音转文字技术将用户的语音输入转换为文本数据。这项技术让用户可以通过说话而非打字与 AI 系统交互，提高了交互的自然性和便捷性，特别适合移动设备、驾驶场景或无障碍应用，是语音助手和实时转录等应用的基础。

### 流式工具调用（Stream-tool-call）
流式工具调用是一种实时处理模式，允许 AI 系统在生成响应的同时调用外部工具，而不必等待完整回答生成后再处理。这种方式大大提高了处理复杂任务的响应速度，让用户体验更加流畅，适合需要多次工具调用的交互场景。

### 流式结果返回（Streaming Response）
流式结果返回是一种实时响应机制，AI 系统边生成内容边返回给用户，而不是等所有内容生成完毕再一次性展示。这种方式显著改善用户等待体验，特别是对于长回答，用户可以立即看到部分内容并开始阅读，提供更自然的交互感受，类似于人类对话中的即时反馈。

## T
### 温度（Temperature）
温度是控制语言模型输出随机性的参数，通常在 0-1 之间。温度越低（接近 0），模型输出越确定和保守，倾向于高概率词汇，适合事实性回答；温度越高（接近 1），输出越多样和创造性，适合创意写作。例如，天气预报可能使用 0.1 的低温度，而故事创作可能使用 0.8 的高温度。

### 文本嵌入（Text Embedding）
文本嵌入是将文本转换为数值向量的过程，使 AI 系统能够理解和处理语言。这些向量捕捉了词汇和句子的语义特征，使计算机可以测量文本间的相似度、聚类相关内容或检索匹配信息。不同的嵌入模型（如 OpenAI 的 text-embedding-ada-002 或 Cohere 的 embed-multilingual）针对不同语言和应用场景进行了优化。

### 工具调用（Tool Calling）
工具调用是 AI 系统识别并使用外部功能的能力，极大扩展了模型的能力边界。例如，语言模型本身不能访问实时数据，但通过调用天气 API，它可以提供当前天气信息；通过调用数据库查询工具，它可以获取最新产品库存；通过调用计算器，它可以执行复杂计算，这使 AI 能够解决超出其训练数据范围的问题。

### TopK
TopK 是控制检索返回结果数量的参数，指定保留相似度最高的前 K 个文本片段。合理设置 TopK 值对 RAG 系统性能至关重要：值太小可能丢失关键信息，值太大则可能引入噪音并增加语言模型处理负担。例如，简单问题可能只需 TopK=3，而复杂问题可能需要 TopK=10 以获取足够背景。

### 核采样（TopP, Nucleus Sampling）
核采样是一种文本生成控制方法，只从累积概率达到阈值 P 的最可能词汇中选择下一个词。与固定选择最高概率词或完全随机不同，TopP 在确定性和创造性间取得平衡。例如，TopP=0.9 意味着模型只考虑概率和占 90% 的词汇，忽略低概率选项，既避免了完全可预测的输出，又不会生成过于随机的内容。

### 思维树（ToT, Tree of Thought）
思维树是一种探索多个推理路径的思考方法，允许模型从不同角度分析问题。类似于人类的"如果...那么..."思考模式，思维树让模型生成多个可能的思考分支，评估每个分支的可行性，然后选择最优路径继续，特别适合解决需要试错或考虑多种可能性的复杂问题。

### 文本转语音（TTS, Text-to-Speech）
文本转语音是将书面文本转换为自然语音的技术，使 AI 系统能以语音方式与用户交流。现代 TTS 系统能生成接近人类的自然语音，支持多种语言、音色和情感表达，广泛应用于有声读物、导航系统、语音助手和无障碍服务，为不同场景和用户提供更自然的交互体验。

## V
### 向量数据库（Vector Database）
向量数据库是专门存储和搜索向量嵌入的数据库系统，是高效语义检索的基础设施。与传统数据库不同，向量数据库针对高维向量相似度搜索进行了优化，能快速从数百万文档中找出语义相近的内容。常见的向量数据库包括 Pinecone、Milvus、Qdrant 等，它们在 RAG 系统、推荐引擎和内容分析中发挥关键作用。

### 向量检索（Vector Retrieval）
向量检索是基于文本向量嵌入相似度的搜索方法，是语义搜索的技术核心。系统首先将用户查询转换为向量，然后在预先计算的文档向量中查找最相似的内容。这种方法能够捕捉深层语义关系，找到表达不同但意思相近的内容，克服了关键词搜索的局限，特别适合处理自然语言查询和概念性问题。

### 视觉能力（Vision）
视觉能力是多模态 LLM 理解和处理图像的功能，允许模型分析用户上传的图片并结合文本生成回答。例如，用户可以上传产品照片询问使用方法，上传菜单照片请求翻译，或上传图表要求分析数据趋势。这种能力大大拓展了 AI 应用场景，使交互更加直观和多样化。

## W
### 工作流（Workflow）
工作流是一种任务编排方式，将复杂 AI 应用拆分为多个独立节点并按特定顺序执行。在 Dify 平台中，开发者可以可视化设计工作流，组合多个处理步骤（如用户输入处理、知识检索、多模型协作、条件分支），构建能处理复杂业务逻辑的 AI 应用，使应用开发既灵活又直观。
